---
layout: docs
page_title: Cluster Peering Overview
description: >-
  Cluster peering establishes communication between independent clusters in Consul, allowing services to interact across datacenters. Learn about the cluster peering process, differences with WAN federation for multi-datacenter deployments, and technical constraints.  
---

# Cluster Peering Overview

This topic provides an overview of cluster peering, which is a process that connects two or more independent clusters so that services deployed to different partitions or datacenters can communicate.

Cluster peering is enabled in Consul by default. Establishing a cluster peering connection is a process that consists of the following steps:

1. Create a peering token in one cluster.
1. Use the peering token to establish peering with a second cluster.
1. Export services between clusters.
1. Create intentions to authorize services for peers.

You can generate peering tokens and initiate connections on any available agent using either the API, CLI, or the Consul UI. The UI does not support exporting services between clusters or authorizing services for peers. If you use the HTTP API, refer to the [`/peering` endpoint reference](/consul/api-docs/peering). If you use the CLI, refer to the [`peering` command reference](/consul/commands/peering).

You can find specific cluster peering configuration and usage information in the following topics:

- To review configuration requirements for gateways, sidecars, exported services, and ACLs, refer to [Cluster peering configuration](/docs/consul/cluster-peering/configuration).
- To create new cluster peering connections, refer to [Establish cluster peering connections](/docs/connect/cluster-peering/create-manage-peering).
- To manage or delete existing cluster peering connections, refer to [Manage cluster peering connections](/consul/docs/cluster-peering/usage/manage-connections).
- To set up service failovers and redirects, refer to [L7 traffic management for cluster peering connections](/consul/docs/cluster-peering/usage/peering-traffic-management).
- To use cluster peering with Kubernetes deployments, refer to [Cluster peering on Kubernetes](/consul/docs/cluster-peering/usage/k8s).
- To use cluster peering with HCP Consul, refer to [Cluster peering in the HCP documentation](/hcp/docs/consul/usage/cluster-peering).

> To learn how to peer clusters and connect services across peers in AWS Elastic Kubernetes Service (EKS) environments, complete the [Consul Cluster Peering on Kubernetes tutorial](/consul/tutorials/developer-mesh/cluster-peering-aws).

## Background

Consul supports cluster peering connections between _[admin partitions](/consul/docs/enterprise/admin-partitions) in different datacenters_. Deployments without an Enterprise license can still use cluster peering because every datacenter automatically includes a default partition. Meanwhile, _admin partitions in the same datacenter_ do not require cluster peering connections because you can export services between them without generating or exchanging a peering token.

The following diagram describes Consul's cluster peering architecture. The `default` partition in the first datacenter has a cluster peering connection with the `web` partition in the second datacenter.

![Diagram of cluster peering with admin partitions](/img/cluster-peering-diagram.png)

Cluster peering leverages several components of Consul's architecture to enforce secure communication between services:

- Peering token
- Mesh gateway
- Exported services
- Service intentions

A _peering token_ contains an embedded secret that you can share to securely establish communication between datacenters. Similar to the [gossip encryption key](/consul/docs/security/encryption#gossip-encryption) that is used to initiate LAN gossip when bootstrapping a datacenter, sharing this token between datacenters enables server agents to recognize authorized requests.

A _mesh gateway_ encrypts outgoing traffic, decrypts incoming traffic, and directs traffic to healthy services. Consul's service mesh features must be enabled in order to use mesh gateways. Unlike the peering token, which is shared between datacenters, mesh gateways support the specific admin partitions they are deployed on.

An _exported service_ is a service with specific upstreams that are explicitly defined in an `exported-services` configuration entry. Exporting services enables services registered in two different [admin partitions](/docs/enterprise/admin-partitions) to communicate.

A _service intention_ establishes secure service-to-service communication in a service mesh. Intentions enable identity-based access between services by exchanging TLS certificates, which the service's sidecar proxy verifies upon each request.

### Cluster peering and WAN federation comparison

WAN federation and cluster peering are different ways to connect services through mesh gateways so that they can communicate across datacenters. WAN federation connects multiple datacenters to make them function as if they were a single cluster, while cluster peering treats each datacenter as a separate cluster. As a result, WAN federation requires a primary datacenter to maintain and replicate global states such as ACLs and configuration entries, but cluster peering does not.

WAN federation and cluster peering also treat encrypted traffic differently. While mesh gateways between WAN federated datacenters use mTLS to keep data encrypted, mesh gateways between peers terminate mTLS sessions, decrypt data to HTTP services, and then re-encrypt traffic to send to services. Data must be decrypted in order to evaluate and apply dynamic routing rules at the destination cluster, which reduces coupling between peers.

Regardless of whether you connect your clusters through WAN federation or cluster peering, human and machine users can use either method to discover services in other clusters or dial them through the service mesh.

|                                                    | WAN Federation | Cluster Peering |
| :------------------------------------------------- | :------------: | :-------------: |
| Connects clusters across datacenters               |    &#9989;     |    &#9989;      |
| Shares support queries and service endpoints       |    &#9989;     |    &#9989;      |
| Connects clusters owned by different operators     |    &#10060;    |    &#9989;      |
| Functions without declaring primary datacenter     |    &#10060;    |    &#9989;      |
| Replicates exported services for service discovery |    &#10060;    |    &#9989;      |
| Gossip protocol: Requires LAN gossip only          |    &#10060;    |    &#9989;      |
| Forwards service requests for service discovery    |    &#9989;     |    &#10060;     |
| Shares key/value stores                            |    &#9989;     |    &#10060;     |
| Can replicate ACL tokens, policies, and roles      |    &#9989;     |    &#10060;     |

## Technical constraints

Consider the following technical constraints:

- Peer names can only contain lowercase characters.
- Services with node, instance, and check definitions totaling more than 8MB cannot be exported to a peer.
- Two admin partitions in the same datacenter cannot be peered. Use [`exported-services`](/consul/docs/connect/config-entries/exported-services#exporting-services-to-peered-clusters) directly.
- The `consul intention` CLI command is not supported. To manage intentions that specify services in peered clusters, use [configuration entries](/consul/docs/connect/config-entries/service-intentions).
- Accessing key/value stores across peers is not supported.
